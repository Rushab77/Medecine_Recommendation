{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #Analysis \n",
    "import matplotlib.pyplot as plt #Visulization\n",
    "import seaborn as sns #Visulization\n",
    "import numpy as np #Analysis \n",
    "from scipy.stats import norm #Analysis \n",
    "from sklearn.preprocessing import StandardScaler #Analysis \n",
    "from scipy import stats #Analysis \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import string\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ba47a95deb9764565521d373d3de8bbd24c6bd7"
   },
   "source": [
    "## 1. Exploration Data Analysis\n",
    "\n",
    "### 1.1. Data understanding\n",
    "\n",
    "\n",
    "First we will import Train data and Test data. The sizes of the two data are as follows:\n",
    "\n",
    "It was data from https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29 and crawled reviews from online pharmaceutical review sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2db18f8c9faff8d19ecb0d3aff3969b37d4bc7ed"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv\", parse_dates=[\"date\"])\n",
    "df_test = pd.read_csv(\"../input/kuc-hackathon-winter-2018/drugsComTest_raw.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ab95e3f3ad6f51426d9732fabb29398c50223b8"
   },
   "outputs": [],
   "source": [
    "print(\"Train shape :\" ,df_train.shape)\n",
    "print(\"Test shape :\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99dad5eb1affeacf030fae4f4a15661c9848979e"
   },
   "source": [
    "This is the result of looking at the data through the head () command. There are six variables except for the unique ID that identifies the individual, and review is the key variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fd9b5423836819b3841d444b91492854ab8865a"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5531c6797f0f890bd3b8c7d4328d25c11d375386"
   },
   "source": [
    "These are additional explanations for variables.\n",
    "\n",
    "- drugName (categorical): name of drug \n",
    "- condition (categorical): name of condition\n",
    "- review (text): patient review \n",
    "- rating (numerical): 10 star patient rating \n",
    "- date (date): date of review entry \n",
    "- usefulCount (numerical): number of users who found review useful\n",
    "\n",
    "The structure of the data is that a patient with a unique ID purchases a drug that meets his condition and writes a review and rating for the drug he/she purchased on the date. Afterwards, if the others read that review and find it helpful, they will click usefulCount, which will add 1 for the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1180500f856ae3f1b772e3b8e2faa393809fdf23"
   },
   "source": [
    "### 1.2. Data understanding\n",
    "\n",
    "First, we will start exploring variables, starting from uniqueID. We compared the unique number of unique IDs and the length of the train data to see if the same customer has written multiple reviews, and there weren't more than one reviews for one customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bf7685ab8278b0709c391aed2560386536552a4"
   },
   "outputs": [],
   "source": [
    "print(\"unique values count of train : \" ,len(set(df_train['uniqueID'].values)))\n",
    "print(\"length of train : \" ,df_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f5f13d517dd6de104f3303ce7ab9c7da5eacd11"
   },
   "source": [
    "DrugName is closely related to condition, so we have analyzed them together. The unique values of the two variables are 3671 and 917, respectively, and there are about 4 drugs for each condition. Let's go ahead and visualize this in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1ce8f6dad73bddd2bf2c2a3a9cab10f2595679c2"
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb2b7aac9798cb96aa4cd032aee6fca2ddb74b4a"
   },
   "outputs": [],
   "source": [
    "condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)\n",
    "condition_dn[0:20].plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Top20 : The number of drugs per condition.\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1b2d517b68e747298b5a17fdb3e6e60aaa1cdaf"
   },
   "source": [
    "As you can see from the picture above, the number of drugs for top eight conditions is about 100 for each condition. On the other hand, it should be noted that the phrase \"3</span> users found this comment helpful\" appears in the condition, which seems like an error in the crawling process. I have looked into it to see in more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0a89c7ebae84c817b3f2e6aab294088c18b261f"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['condition']=='3</span> users found this comment helpful.'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5585d77c9e6c06707fae1e82aea83abc49d75acb"
   },
   "source": [
    "It is expected that for structure of '</ span> users found this comment helpful.' phrase, there will be not only 3, but also 4 as shown above, and other numbers as well. We will remove these data in the future preprocessing.\n",
    "\n",
    "The following are the low 20 conditions of 'drugs per condition'. As you can see, the number is all 1. Considering the recommendation system, it is not feasible to recommend with that when there is only one product. Therefore, we will analyze only the conditions that have at least 2 drugs per condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f46bf457b8c4b0a7b4ac2d476f42e38323ca483a"
   },
   "outputs": [],
   "source": [
    "condition_dn = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)\n",
    "\n",
    "condition_dn[condition_dn.shape[0]-20:condition_dn.shape[0]].plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Bottom20 : The number of drugs per condition.\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd9d70cb99c89d6def5496da845533aa682e68be"
   },
   "source": [
    "Next, let's have a look at the review. First, noticeable parts are the html strings like \\ r \\ n, and the parts that express emotions in parentheses such as (very unusual for him) and (a good thing) and words in capital letters like MUCH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c283d11b69ada1b9defd9f5c9fab9d69022b631"
   },
   "outputs": [],
   "source": [
    "df_train['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89a40ddaee7f0c89ca9d0ad8d14c9e56c0f47b0b"
   },
   "source": [
    "In addition, there were some words with errors like didn&# 039;t for didn't, and also characters like ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7d59b1d8ab8cd481ef1d99b91862fbcd34032d4"
   },
   "outputs": [],
   "source": [
    "df_train['review'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "253b7284fb0685ddff06c1328d2e52a54c1ee884"
   },
   "source": [
    "We will delete these parts in preprocessing as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9a3e123470563259697ac03491b08d125493757"
   },
   "source": [
    "Next up, it's Word Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ba8744fb8f95488d63b517eb64d61ee43afbee0d"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc kernel \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\n",
    "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n",
    "                   title = None, title_size=40, image_color=False):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n",
    "    stopwords = stopwords.union(more_stopwords)\n",
    "\n",
    "    wordcloud = WordCloud(background_color='white',\n",
    "                    stopwords = stopwords,\n",
    "                    max_words = max_words,\n",
    "                    max_font_size = max_font_size, \n",
    "                    random_state = 42,\n",
    "                    width=800, \n",
    "                    height=400,\n",
    "                    mask = mask)\n",
    "    wordcloud.generate(str(text))\n",
    "    \n",
    "    plt.figure(figsize=figure_size)\n",
    "    if image_color:\n",
    "        image_colors = ImageColorGenerator(mask);\n",
    "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
    "        plt.title(title, fontdict={'size': title_size,  \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    else:\n",
    "        plt.imshow(wordcloud);\n",
    "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    plt.axis('off');\n",
    "    plt.tight_layout()  \n",
    "    \n",
    "plot_wordcloud(df_all[\"review\"], title=\"Word Cloud of review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab15f4931cc199933f76bb659d4825287827fe3d"
   },
   "source": [
    "Next, we will classify 1 ~ 5 as negative, and 6 ~ 10 as positive, and we will check through 1 ~ 4 grams which corpus best classifies emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "72569a2d173760ec20f1893ee67c74e42773f186"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "df_all_6_10 = df_all[df_all[\"rating\"]>5]\n",
    "df_all_1_5 = df_all[df_all[\"rating\"]<6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2d28e3c380acba0078318c33063d51ee86943555"
   },
   "outputs": [],
   "source": [
    "## custom function for ngram generation ##\n",
    "def generate_ngrams(text, n_gram=1):\n",
    "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n",
    "    ngrams = zip(*[token[i:] for i in range(n_gram)])\n",
    "    return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "## custom function for horizontal bar chart ##\n",
    "def horizontal_bar_chart(df, color):\n",
    "    trace = go.Bar(\n",
    "        y=df[\"word\"].values[::-1],\n",
    "        x=df[\"wordcount\"].values[::-1],\n",
    "        showlegend=False,\n",
    "        orientation = 'h',\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "        ),\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "## Get the bar chart from rating  8 to 10 review ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_1_5[\"review\"]:\n",
    "    for word in generate_ngrams(sent):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace0 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
    "\n",
    "## Get the bar chart from rating  4 to 7 review ##\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_6_10[\"review\"]:\n",
    "    for word in generate_ngrams(sent):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'blue')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,\n",
    "                          subplot_titles=[\"Frequent words of rating 1 to 5\", \n",
    "                                          \"Frequent words of rating 6 to 10\"])\n",
    "fig.append_trace(trace0, 1, 1)\n",
    "fig.append_trace(trace1, 1, 2)\n",
    "fig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\n",
    "py.iplot(fig, filename='word-plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d12cc47d486b171f127de48d6dbe640bfbdc4ad"
   },
   "source": [
    "When you use 1-gram, you can see that the top 5 words have the same contents, although the order of left (negative) and right (positive) are different. This means when we analyze the text with a single corpus, it does not classify the emotion well. So, we will expand the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "03e56f5eb12b5d2e738191a2ebfb61a85a2b963a"
   },
   "outputs": [],
   "source": [
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_1_5[\"review\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'orange')\n",
    "\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_6_10[\"review\"]:\n",
    "    for word in generate_ngrams(sent,2):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace2 = horizontal_bar_chart(fd_sorted.head(50), 'orange')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,horizontal_spacing=0.15,\n",
    "                          subplot_titles=[\"Frequent biagrams of rating 1 to 5\", \n",
    "                                          \"Frequent biagrams of rating 6 to 10\"])\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig['layout'].update(height=1200, width=1000, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Count Plots\")\n",
    "py.iplot(fig, filename='word-plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "faa15e62d9bd51b7e538a84f89ad6061efc4c48b"
   },
   "source": [
    "Likewise, in 2-gram, the contents of the top five corpus are similar, and it is hard to classify positive and negative. In addition, 'side effects' and 'side effects.' are interpreted differently, which means preprocessing of review data is necessary. However, you can see that this is better to classify emotions rather than previous 1-grams, like side effects, weight gain, and highly recommend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cae502a170fe1665fd9aff62a257c04d111887b8"
   },
   "outputs": [],
   "source": [
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_1_5[\"review\"]:\n",
    "    for word in generate_ngrams(sent,3):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'green')\n",
    "\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_6_10[\"review\"]:\n",
    "    for word in generate_ngrams(sent,3):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace2 = horizontal_bar_chart(fd_sorted.head(50), 'green')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,horizontal_spacing=0.15,\n",
    "                          subplot_titles=[\"Frequent trigrams of rating 1 to 5\", \n",
    "                                          \"Frequent trigrams of rating 6 to 10\"])\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig['layout'].update(height=1200, width=1600, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\n",
    "py.iplot(fig, filename='word-plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2ff80f6d7cf321f40f65c6330a2ad902f59659a"
   },
   "source": [
    "From 3-gram you can see that there is a difference between positive and negative corpus. Bad side effects, birth control pills, negative side effects are corpus that classify positive and negative. However, both positive and negative parts can be thought that it has missing parts that reverses the context, such as' not' in front of a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "b59a9e02961f89349684d69e793fc3270b103022"
   },
   "outputs": [],
   "source": [
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_1_5[\"review\"]:\n",
    "    for word in generate_ngrams(sent,4):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace1 = horizontal_bar_chart(fd_sorted.head(50), 'red')\n",
    "\n",
    "freq_dict = defaultdict(int)\n",
    "for sent in df_all_6_10[\"review\"]:\n",
    "    for word in generate_ngrams(sent,4):\n",
    "        freq_dict[word] += 1\n",
    "fd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\n",
    "fd_sorted.columns = [\"word\", \"wordcount\"]\n",
    "trace2 = horizontal_bar_chart(fd_sorted.head(50), 'red')\n",
    "\n",
    "# Creating two subplots\n",
    "fig = tools.make_subplots(rows=1, cols=2, vertical_spacing=0.04,horizontal_spacing=0.15,\n",
    "                          subplot_titles=[\"Frequent 4-grams of rating 1 to 5\", \n",
    "                                          \"Frequent 4-grams of rating 6 to 10\"])\n",
    "fig.append_trace(trace1, 1, 1)\n",
    "fig.append_trace(trace2, 1, 2)\n",
    "fig['layout'].update(height=1200, width=1600, paper_bgcolor='rgb(233,233,233)', title=\"4-grams Count Plots\")\n",
    "py.iplot(fig, filename='word-plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d2ce70ff984cda025a8edbd820f756bf6feacd5e"
   },
   "source": [
    "Clearly, 4-gram classifies emotions much betther than other grams. Therefore, we will use 4-gram to build deep learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8617d65924307b6e97c5828b680a0f6bedf4a360"
   },
   "source": [
    "Next, we will look for relationship between rating and weather. First of all, we will count the number of ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d119068cf249e999a8f216e0167af8e628fd70a"
   },
   "outputs": [],
   "source": [
    "rating = df_all['rating'].value_counts().sort_values(ascending=False)\n",
    "rating.plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Count of rating values\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d23525d7fd8b400a4786f86216d663facc7c46ca"
   },
   "source": [
    "Most people choose four values; 10, 9, 1, 8, and the number of 10 is more than twice as many as the others. With this, we can see that the percentage of positives is higher than negative, and people's reactions are extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f7386932ed0289c2623059e0636084af3ede94c"
   },
   "source": [
    "Next, we will check the number of reviews and percentage of ratings according to weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14b215ad07c7d5733a4d950043d17f905732c222"
   },
   "outputs": [],
   "source": [
    "# Code in https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-elo\n",
    "# SRK - Simple Exploration Notebook \n",
    "\n",
    "cnt_srs = df_all['date'].dt.year.value_counts()\n",
    "cnt_srs = cnt_srs.sort_index()\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('year', fontsize=12)\n",
    "plt.ylabel('', fontsize=12)\n",
    "plt.title(\"Number of reviews in year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16dcf7a747d2eb06895c49ee6fd476e179aed2ba"
   },
   "outputs": [],
   "source": [
    "df_all['year'] = df_all['date'].dt.year\n",
    "rating = df_all.groupby('year')['rating'].mean()\n",
    "rating.plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Mean rating in year\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7dfdffd170217e7d753ea6d28a6630b7f494041c"
   },
   "outputs": [],
   "source": [
    "# Code in https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-elo\n",
    "# SRK - Simple Exploration Notebook \n",
    "\n",
    "cnt_srs = df_all['date'].dt.month.value_counts()\n",
    "cnt_srs = cnt_srs.sort_index()\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color='green')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('month', fontsize=12)\n",
    "plt.ylabel('', fontsize=12)\n",
    "plt.title(\"Number of reviews in month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a6c95402fb6d936ea4799d93f2c9eeab47585db"
   },
   "outputs": [],
   "source": [
    "df_all['month'] = df_all['date'].dt.month\n",
    "rating = df_all.groupby('month')['rating'].mean()\n",
    "rating.plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Mean rating in month\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25da863d027db802c5e3cf11b6b77c6ecf606ebe"
   },
   "source": [
    "Interestingly, you can see that the average rating differs by year, but it is similar by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "808970cc32f9a7e573ab81b54b2afe12f86729c4"
   },
   "outputs": [],
   "source": [
    "df_all['day'] = df_all['date'].dt.day\n",
    "rating = df_all.groupby('day')['rating'].mean()\n",
    "rating.plot(kind=\"bar\", figsize = (14,6), fontsize = 10,color=\"green\")\n",
    "plt.xlabel(\"\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Mean rating in day\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0049b5a13be3ddb3b0147ebc83ba42d1952eb109"
   },
   "source": [
    "We checked whether the day of the week affects the rating like salary day, but it does not make a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46c8c44e5e61e6a4139db9cbc9b0c10533923f7e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "sns.distplot(df_all[\"usefulCount\"].dropna(),color=\"green\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel('', fontsize=12)\n",
    "plt.ylabel('', fontsize=12)\n",
    "plt.title(\"Distribution of usefulCount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b8c382bf6e31efc48656e098dfefc76cf88deff"
   },
   "outputs": [],
   "source": [
    "df_all[\"usefulCount\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4bb7102e270fcfa98d9659a577de26ef9611e016"
   },
   "source": [
    "If you look at the distribution of usefulCount, you can see that the difference between minimum and maximum is 1291, which is high. In addition, the deviation is huge, which is 36. The reason for this is that the more drugs people look for, the more people read the review no matter their contents are good or bad, which makes the usefulcount very high. So when we create the model, we will normalize it by conditions, considering people's accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "541ea018457f9107abf3f2c11051b39b2b17198d"
   },
   "source": [
    "### 1.3 Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe78d3aec92fbac8f64723535bb47c09a40231c3"
   },
   "outputs": [],
   "source": [
    "percent = (df_all.isnull().sum()).sort_values(ascending=False)\n",
    "percent.plot(kind=\"bar\", figsize = (14,6), fontsize = 10, color='green')\n",
    "plt.xlabel(\"Columns\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Total Missing Value \", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcbd81bf2a4013c6ce9cb81067ab15684171203c"
   },
   "outputs": [],
   "source": [
    "print(\"Missing value (%):\", 1200/df_all.shape[0] *100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97c340b894003a1ad2fc0b6e589ae351cbd3e253"
   },
   "source": [
    "We will delete because the percentage is lower than 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c9a363d9fc7b266ee9c8a390d3c841b71126037"
   },
   "source": [
    "## 2. Date Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32e167512298155137e85532b01158049819c100"
   },
   "source": [
    "### 2.1. Missing Values Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af5d3f3c7fccd92a93413514030b6a33b0a89052"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(axis=0)\n",
    "df_test = df_test.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1012e7c255ad73cf21048fd6534cb20bbcf6f1ce"
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train,df_test]).reset_index()\n",
    "del df_all['index']\n",
    "percent = (df_all.isnull().sum()).sort_values(ascending=False)\n",
    "percent.plot(kind=\"bar\", figsize = (14,6), fontsize = 10, color='green')\n",
    "plt.xlabel(\"Columns\", fontsize = 20)\n",
    "plt.ylabel(\"\", fontsize = 20)\n",
    "plt.title(\"Total Missing Value \", fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aaceaccc91bf0a846df8a6377558d89824a01c9c"
   },
   "source": [
    "### 2.2 Condition Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "127f1391018fc3049ea14df7e5ea43c96812a9c3"
   },
   "source": [
    "We will delete the sentences with the form above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4269e93fb9a64b79f9e74db338d4df28e2ba0f8"
   },
   "outputs": [],
   "source": [
    "all_list = set(df_all.index)\n",
    "span_list = []\n",
    "for i,j in enumerate(df_all['condition']):\n",
    "    if '</span>' in j:\n",
    "        span_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8545b5cdc904897a886bfad95fadf0196515f420"
   },
   "outputs": [],
   "source": [
    "new_idx = all_list.difference(set(span_list))\n",
    "df_all = df_all.iloc[list(new_idx)].reset_index()\n",
    "del df_all['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1a5f5508ba8367b0e1fe86bbd9356965d104a98"
   },
   "source": [
    "Next, we will delete conditions with only one drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13324f1aaed4de4d20c53cd52a6ee2dca301d42a"
   },
   "outputs": [],
   "source": [
    "df_condition = df_all.groupby(['condition'])['drugName'].nunique().sort_values(ascending=False)\n",
    "df_condition = pd.DataFrame(df_condition).reset_index()\n",
    "df_condition.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a1341f12498cbbd65e8e7cd1ab9789e94f5468e"
   },
   "outputs": [],
   "source": [
    "df_condition_1 = df_condition[df_condition['drugName']==1].reset_index()\n",
    "df_condition_1['condition'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edf19fcd7a99264a5436034d648b20d0bff2fa7b"
   },
   "outputs": [],
   "source": [
    "all_list = set(df_all.index)\n",
    "condition_list = []\n",
    "for i,j in enumerate(df_all['condition']):\n",
    "    for c in list(df_condition_1['condition']):\n",
    "        if j == c:\n",
    "            condition_list.append(i)\n",
    "            \n",
    "new_idx = all_list.difference(set(condition_list))\n",
    "df_all = df_all.iloc[list(new_idx)].reset_index()\n",
    "del df_all['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb80a22040f4f9ca03311ce9e1ea782eb8ee89ad"
   },
   "source": [
    "### 2.3 Review Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5afbc9c8b87abc646ed24fb5a0feadd5996169a1"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da532e45210e8a15eb1361aad88fc749eebea620"
   },
   "source": [
    "- \\r\\n : we need to convert html grammer\n",
    "- ... , &#039; : deal with not alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "6f546ffb47ae31a30903d4075e8c514a45c7a951"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "#stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "dde27caf5b374b0f3f0c2acd9d038daba43c4c31"
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-qiqc kernel \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\n",
    "def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n",
    "                   title = None, title_size=40, image_color=False):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n",
    "    stopwords = stopwords.union(more_stopwords)\n",
    "\n",
    "    wordcloud = WordCloud(background_color='white',\n",
    "                    stopwords = stopwords,\n",
    "                    max_words = max_words,\n",
    "                    max_font_size = max_font_size, \n",
    "                    random_state = 42,\n",
    "                    width=800, \n",
    "                    height=400,\n",
    "                    mask = mask)\n",
    "    wordcloud.generate(str(text))\n",
    "    \n",
    "    plt.figure(figsize=figure_size)\n",
    "    if image_color:\n",
    "        image_colors = ImageColorGenerator(mask);\n",
    "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
    "        plt.title(title, fontdict={'size': title_size,  \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    else:\n",
    "        plt.imshow(wordcloud);\n",
    "        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
    "                                  'verticalalignment': 'bottom'})\n",
    "    plt.axis('off');\n",
    "    plt.tight_layout()  \n",
    "    \n",
    "plot_wordcloud(stops, title=\"Word Cloud of stops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "85cf983ca3865accc2b5630f8ef4430c4fd70e92"
   },
   "source": [
    "First, let's see what words are used as stopwords. There are many words that include not, like needn't. These words are key parts of emotional analysis, so we will remove them from stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "275f9e83f9935d0891fa11a6440b6caf4604e5d3"
   },
   "outputs": [],
   "source": [
    "not_stop = [\"aren't\",\"couldn't\",\"didn't\",\"doesn't\",\"don't\",\"hadn't\",\"hasn't\",\"haven't\",\"isn't\",\"mightn't\",\"mustn't\",\"needn't\",\"no\",\"nor\",\"not\",\"shan't\",\"shouldn't\",\"wasn't\",\"weren't\",\"wouldn't\"]\n",
    "for i in not_stop:\n",
    "    stops.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "386e3e954a0b1db1d5e7e739f6928ba245e3b9c0"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8368a97c8e435adb9f07d144f494fc60a083a5a1"
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    # 1. Delete HTML \n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    # 2. Make a space\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    # 3. lower letters\n",
    "    words = letters_only.lower().split()\n",
    "    # 5. Stopwords \n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. Stemming\n",
    "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    # 7. space join words\n",
    "    return( ' '.join(stemming_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be46dc37dd26328efedf9ca166b5635e0f13fb53"
   },
   "outputs": [],
   "source": [
    "%time df_all['review_clean'] = df_all['review'].apply(review_to_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1bdd3b519e1df8d4959c77274910f24fb0d35440"
   },
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f6301c9d03a198e3ce7b22b172970152ee21b6a"
   },
   "source": [
    "### 3.1. Deep Learning Model Using N-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6adae84cb2d9d4e0588cb10033c17447bf976d58"
   },
   "outputs": [],
   "source": [
    "# Make a rating\n",
    "df_all['sentiment'] = df_all[\"rating\"].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba7f1a884407f9247915b3b6757219501cf13a15"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_all, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6a9555e8c90e09fab2edaf2107c6b6bfcb588fd"
   },
   "outputs": [],
   "source": [
    "# https://github.com/corazzon/KaggleStruggle/blob/master/word2vec-nlp-tutorial/tutorial-part-1.ipynb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', \n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None, \n",
    "                             stop_words = None, \n",
    "                             min_df = 2, # 토큰이 나타날 최소 문서 개수\n",
    "                             ngram_range=(4, 4),\n",
    "                             max_features = 20000\n",
    "                            )\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b983fc4de6f9e7e3be07445c418ef1060d6f02f"
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28160335/plot-a-document-tfidf-2d-graph\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b1e9c628a7dec80e1e863f7acffdae64e3ae7ab"
   },
   "outputs": [],
   "source": [
    "%time train_data_features = pipeline.fit_transform(df_train['review_clean'])\n",
    "%time test_data_features = pipeline.fit_transform(df_test['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f71f9a7ad9cec9777814bf2746bc4237116b8b35"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ce3dfe83a105f9628b61ee107c3fed27f252fb40"
   },
   "outputs": [],
   "source": [
    "#Source code in keras 김태영'blog\n",
    "# 0. Package\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import random\n",
    "\n",
    "# 1. Dataset\n",
    "y_train = df_train['sentiment']\n",
    "y_test = df_test['sentiment']\n",
    "solution = y_test.copy()\n",
    "\n",
    "# 2. Model Structure\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(200, input_shape=(20000,)))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(300))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 3. Model compile\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea8db26bcd3cba382ff381684b3f229d381bca5f"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48b6724a5d7b994c15bd4505bccdb6b3e602ba21"
   },
   "outputs": [],
   "source": [
    "# 4. Train model\n",
    "hist = model.fit(train_data_features, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "# 5. Traing process\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.set_ylim([0.0, 1.0])\n",
    "acc_ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 6. Evaluation\n",
    "loss_and_metrics = model.evaluate(test_data_features, y_test, batch_size=32)\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d678d5dd391fc455de2cad0b4b8f6fe76374583c"
   },
   "outputs": [],
   "source": [
    "sub_preds_deep = model.predict(test_data_features,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "603ee53139269ed2a9b009a65a9b026b9ce11bf4"
   },
   "source": [
    "### 3.2 Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fee63f2564ce6ad240d6b2e3d1aaf028e98c15a8"
   },
   "source": [
    "To improve the low accuracy, we will use machine learning. First of all, this is the sentiment analysis model using only usefulCount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2c4d7f24d1f25d99979687c2101f60bf202d2f04"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "target = df_train['sentiment']\n",
    "feats = ['usefulCount']\n",
    "\n",
    "sub_preds = np.zeros(df_test.shape[0])\n",
    "\n",
    "trn_x, val_x, trn_y, val_y = train_test_split(df_train[feats], target, test_size=0.2, random_state=42) \n",
    "feature_importance_df = pd.DataFrame() \n",
    "    \n",
    "clf = LGBMClassifier(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=30,\n",
    "        #colsample_bytree=.9,\n",
    "        subsample=.9,\n",
    "        max_depth=7,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01,\n",
    "        min_child_weight=2,\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "        )\n",
    "        \n",
    "clf.fit(trn_x, trn_y, \n",
    "        eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "        verbose=100, early_stopping_rounds=100  #30\n",
    "    )\n",
    "\n",
    "sub_preds = clf.predict(df_test[feats])\n",
    "        \n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = feats\n",
    "fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1684caab656ca830228cc230871ac3e3d961352a"
   },
   "outputs": [],
   "source": [
    "solution = df_test['sentiment']\n",
    "confusion_matrix(y_pred=sub_preds, y_true=solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29474d09e5ec8832fbacc39d5738472c8470d768"
   },
   "source": [
    "We will add variables for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e6032557347dab3092ecfa45baec6f214b49017"
   },
   "outputs": [],
   "source": [
    "len_train = df_train.shape[0]\n",
    "df_all = pd.concat([df_train,df_test])\n",
    "del df_train, df_test;\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0ae19226fc6ec7c02e0510a51ec7dd05724da876"
   },
   "outputs": [],
   "source": [
    "df_all['date'] = pd.to_datetime(df_all['date'])\n",
    "df_all['day'] = df_all['date'].dt.day\n",
    "df_all['year'] = df_all['date'].dt.year\n",
    "df_all['month'] = df_all['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd4f0e2c792a6d084979c548596df92848d06856"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "reviews = df_all['review_clean']\n",
    "\n",
    "Predict_Sentiment = []\n",
    "for review in tqdm(reviews):\n",
    "    blob = TextBlob(review)\n",
    "    Predict_Sentiment += [blob.sentiment.polarity]\n",
    "df_all[\"Predict_Sentiment\"] = Predict_Sentiment\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1091f4a36ae81c2973ecdb6fac964c646d93ba0f"
   },
   "outputs": [],
   "source": [
    "np.corrcoef(df_all[\"Predict_Sentiment\"], df_all[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6deb741f0941fa04ac1a87e9343f9079b5c1a83c"
   },
   "outputs": [],
   "source": [
    "np.corrcoef(df_all[\"Predict_Sentiment\"], df_all[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38f83afcdd82bb469b8d6b6b90e9b60b6921219e"
   },
   "outputs": [],
   "source": [
    "reviews = df_all['review']\n",
    "\n",
    "Predict_Sentiment = []\n",
    "for review in tqdm(reviews):\n",
    "    blob = TextBlob(review)\n",
    "    Predict_Sentiment += [blob.sentiment.polarity]\n",
    "df_all[\"Predict_Sentiment2\"] = Predict_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8952070fd762f0d27667940b8a9c764a75eff67e"
   },
   "outputs": [],
   "source": [
    "np.corrcoef(df_all[\"Predict_Sentiment2\"], df_all[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69fa8972589337694b89e823a10e8134cd0b8ed2"
   },
   "outputs": [],
   "source": [
    "np.corrcoef(df_all[\"Predict_Sentiment2\"], df_all[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6488abff05ebf6698e01cfae7550d977fb8a6b02"
   },
   "outputs": [],
   "source": [
    "#문장길이 (줄바꿈표시가 몇번나왔는지 셈)\n",
    "df_all['count_sent']=df_all[\"review\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n",
    "\n",
    "#Word count in each comment:(단어갯수)\n",
    "df_all['count_word']=df_all[\"review_clean\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "#Unique word count(unique한 단어 갯수)\n",
    "df_all['count_unique_word']=df_all[\"review_clean\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "#Letter count(리뷰길이)\n",
    "df_all['count_letters']=df_all[\"review_clean\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "#punctuation count(특수문자)\n",
    "df_all[\"count_punctuations\"] = df_all[\"review\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "#upper case words count(전부다 대문자인 단어 갯수)\n",
    "df_all[\"count_words_upper\"] = df_all[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "#title case words count(첫글자가 대문자인 단어 갯수)\n",
    "df_all[\"count_words_title\"] = df_all[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "#Number of stopwords(불용어 갯수)\n",
    "df_all[\"count_stopwords\"] = df_all[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stops]))\n",
    "\n",
    "#Average length of the words(평균단어길이)\n",
    "df_all[\"mean_word_len\"] = df_all[\"review_clean\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfeeba96c727574a58ade17ffdab2f1d7d7ebf62"
   },
   "source": [
    "We added a season variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a4129d1c7c60b57014db60a990bbeef5e73e223"
   },
   "outputs": [],
   "source": [
    "df_all['season'] = df_all[\"month\"].apply(lambda x: 1 if ((x>2) & (x<6)) else(2 if (x>5) & (x<9) else (3 if (x>8) & (x<12) else 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "025efc594ab90e1c2e4c0f32a3eca56aa063976c"
   },
   "source": [
    "We normalized useful count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d001d32f4216747d3ad768c3d136ab4974c21f0f"
   },
   "outputs": [],
   "source": [
    "df_train = df_all[:len_train]\n",
    "df_test = df_all[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "99577a2f98a7e997ff0d1c317da32219cbadf506"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "target = df_train['sentiment']\n",
    "feats = ['usefulCount','day','year','month','Predict_Sentiment','Predict_Sentiment2', 'count_sent',\n",
    " 'count_word', 'count_unique_word', 'count_letters', 'count_punctuations',\n",
    " 'count_words_upper', 'count_words_title', 'count_stopwords', 'mean_word_len', 'season']\n",
    "\n",
    "sub_preds = np.zeros(df_test.shape[0])\n",
    "\n",
    "trn_x, val_x, trn_y, val_y = train_test_split(df_train[feats], target, test_size=0.2, random_state=42) \n",
    "feature_importance_df = pd.DataFrame() \n",
    "    \n",
    "clf = LGBMClassifier(\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.10,\n",
    "        num_leaves=30,\n",
    "        #colsample_bytree=.9,\n",
    "        subsample=.9,\n",
    "        max_depth=7,\n",
    "        reg_alpha=.1,\n",
    "        reg_lambda=.1,\n",
    "        min_split_gain=.01,\n",
    "        min_child_weight=2,\n",
    "        silent=-1,\n",
    "        verbose=-1,\n",
    "        )\n",
    "        \n",
    "clf.fit(trn_x, trn_y, \n",
    "        eval_set= [(trn_x, trn_y), (val_x, val_y)], \n",
    "        verbose=100, early_stopping_rounds=100  #30\n",
    "    )\n",
    "\n",
    "sub_preds = clf.predict(df_test[feats])\n",
    "        \n",
    "fold_importance_df = pd.DataFrame()\n",
    "fold_importance_df[\"feature\"] = feats\n",
    "fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a666baea3f58fe9c6d5292cfe24391f0ebb903e8"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_pred=sub_preds, y_true=solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "208f503ba23bc2d8412b27c61772371315ffef78"
   },
   "outputs": [],
   "source": [
    "cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "    by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c8feb72b512e8032016da05083eebe80c184c58a"
   },
   "source": [
    "### 3.3 Dictionary_Sentiment_Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d26dbb8f59e4a7d4d9518e6b14e485cd79b6a08"
   },
   "source": [
    "Because the package used for prediction of 'Predict value' is formed with movie review data, it can be unsuitable for this project which analyzes reviews for drugs. To make up for this, we conducted additional emotional analysis using the Harvard emotional dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "62f0f62033a5f3661c119213ed322b880a545da4"
   },
   "outputs": [],
   "source": [
    "# import dictionary data\n",
    "word_table = pd.read_csv(\"../input/dictionary/inquirerbasic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3ea9c71d4d8c47a991b2ddd11143699af5c6ac0"
   },
   "outputs": [],
   "source": [
    "word_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "384ba6b02f776f9080d57c18a7f3740b3a2236d3"
   },
   "outputs": [],
   "source": [
    "##1. make list of sentiment\n",
    "#Positiv word list   \n",
    "temp_Positiv = []\n",
    "Positiv_word_list = []\n",
    "for i in range(0,len(word_table.Positiv)):\n",
    "    if word_table.iloc[i,2] == \"Positiv\":\n",
    "        temp = word_table.iloc[i,0].lower()\n",
    "        temp1 = re.sub('\\d+', '', temp)\n",
    "        temp2 = re.sub('#', '', temp1) \n",
    "        temp_Positiv.append(temp2)\n",
    "\n",
    "Positiv_word_list = list(set(temp_Positiv))\n",
    "len(temp_Positiv)\n",
    "len(Positiv_word_list)  #del temp_Positiv\n",
    "\n",
    "#Negativ word list          \n",
    "temp_Negativ = []\n",
    "Negativ_word_list = []\n",
    "for i in range(0,len(word_table.Negativ)):\n",
    "    if word_table.iloc[i,3] == \"Negativ\":\n",
    "        temp = word_table.iloc[i,0].lower()\n",
    "        temp1 = re.sub('\\d+', '', temp)\n",
    "        temp2 = re.sub('#', '', temp1) \n",
    "        temp_Negativ.append(temp2)\n",
    "\n",
    "Negativ_word_list = list(set(temp_Negativ))\n",
    "len(temp_Negativ)\n",
    "len(Negativ_word_list)  #del temp_Negativ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73ac447f7fad4fdef122155d74cbe58e00fc57ec"
   },
   "source": [
    "We counted the number of words in review_clean which are included in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bddbe0aacbe8480869d1935d49bac6397827cd6c"
   },
   "outputs": [],
   "source": [
    "##2. counting the word 98590\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary = Positiv_word_list)\n",
    "content = df_test['review_clean']\n",
    "X = vectorizer.fit_transform(content)\n",
    "f = X.toarray()\n",
    "f = pd.DataFrame(f)\n",
    "f.columns=Positiv_word_list\n",
    "df_test[\"num_Positiv_word\"] = f.sum(axis=1)\n",
    "\n",
    "vectorizer2 = CountVectorizer(vocabulary = Negativ_word_list)\n",
    "content = df_test['review_clean']\n",
    "X2 = vectorizer2.fit_transform(content)\n",
    "f2 = X2.toarray()\n",
    "f2 = pd.DataFrame(f2)\n",
    "f2.columns=Negativ_word_list\n",
    "df_test[\"num_Negativ_word\"] = f2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63f678116cb243d737982bb6ae8e9dbd3da49094",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##3. decide sentiment\n",
    "df_test[\"Positiv_ratio\"] = df_test[\"num_Positiv_word\"]/(df_test[\"num_Positiv_word\"]+df_test[\"num_Negativ_word\"])\n",
    "df_test[\"sentiment_by_dic\"] = df_test[\"Positiv_ratio\"].apply(lambda x: 1 if (x>=0.5) else (0 if (x<0.5) else 0.5))\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da172c9523937834f34ba3d2a137d73c0ad41443"
   },
   "source": [
    "We defined Positiv_ratio = the number of positive words / (the number of positive words+the number of negative words) If the ratio is lower than 0.5, we classified as negative and if it's higher than 0.5, we classified as positive. With remainders, we classified as neutral, which includes the sentence without either positive or negative words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ebc76b1ffbc7eafc6632f8c89949040812a704eb"
   },
   "source": [
    "As mentioned earlier, we have normalized usefulCount by condition to solve the problem that usefulCount shows bias depending on condition. You can then add three predicted emotion values and multiply them by the normalized usefulCount to get the predicted value.\n",
    "\n",
    "Now, we can recommend drug by condition in order of final predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85cf8b344e09601d6fb5951ece7c9e2601c3ed8d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def userful_count(data):\n",
    "    grouped = data.groupby(['condition']).size().reset_index(name='user_size')\n",
    "    data = pd.merge(data,grouped,on='condition',how='left')\n",
    "    return data\n",
    "#___________________________________________________________\n",
    "df_test =  userful_count(df_test) \n",
    "df_test['usefulCount'] = df_test['usefulCount']/df_test['user_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff0e4b2e3a4c9d6b82b2f32a9ac8601f2a18573d"
   },
   "outputs": [],
   "source": [
    "df_test['deep_pred'] = sub_preds_deep\n",
    "df_test['machine_pred'] = sub_preds\n",
    "\n",
    "df_test['total_pred'] = (df_test['deep_pred'] + df_test['machine_pred'] + df_test['sentiment_by_dic'])*df_test['usefulCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46e8ff4f7569243d85c489e5034e37850ce623f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.groupby(['condition','drugName']).agg({'total_pred' : ['mean']})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f03520f613d39b0721baae76ebca2be0f722cdb3"
   },
   "source": [
    "## 4. Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1fac2f7625a0a7f7e8d349adcff64e0e50bf75e6"
   },
   "source": [
    "Our team set the topic as recommending the right medicine for the patient's condition with reviews and proceeded the project according to the topic with the data exploration, data preprocessing and modeling. In the data exploration section, we looked at the forms of data using visualization techniques and statistical techniques. We also looked for n-grams that can best represent emotions, and the relationship with date and rating. The next step was to preprocess the data according to the topic we set, such as removing the condition that has only one drug for recommendation. In the process of modeling, we used deep learning model with n-gram, and additionally used a machine learning model called Lightgbm to overcome the limitation of natural language processing. In addition, we conducted emotional analysis using emotional word dictionary to overcome limitations of package formed with movie data. In addition, we nomalized usefulcount by condition for better reliability. These steps allowed us to calculate the final predicted value and recommend the appropriate drug for each condition according to the order of the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24aedde8fec7cde0d040d027ba5e9ff76667de70"
   },
   "source": [
    "## 5. Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "959209a6bc1c99eb5526699b8fc60702521e5bfe"
   },
   "source": [
    "In conclusion, these are the limitations we had during the project.\n",
    "\n",
    "1. Sentiment analysis using sentiment word dictionary has low reliability when the number of positive and negative words is small. For example, if there are 0 positive words and 1 negative word, it is classified as negative. Therefore, if the number of sentiment words is 5 or less, we could exclude the observations.\n",
    "2. To ensure the reliability of the predicted values, we normalized usefulCount and multiplied it to the predicted values. However, usefulCount may tend to be higher for older reviews as the number of cumulated site visitors increases. Therefore, we should have also considered time when normalizing usefulCount.\n",
    "3. If the emotion is positive, the reliability should be increased to the positive side, and if it is negative, the reliability should be increased toward the negative side. However, we simply multiplied the usefulCount for reliability and did not consider this part. So we should have multiplied considering the sign of usefulCount according to different kinds of emotion.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
